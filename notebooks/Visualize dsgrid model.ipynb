{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e975bd88",
   "metadata": {},
   "source": [
    "# Visualize dsgrid model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import copy\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import webcolors\n",
    "\n",
    "from dsgrid.dataformat.datafile import Datafile\n",
    "from dsgrid.dataformat.datatable import Datatable\n",
    "from dsgrid.dataformat.enumeration import census_divisions, conus, conus_states, enumdata_folder\n",
    "from dsgrid.dataformat.dimmap import mappings\n",
    "from dsgrid.helpers import ensure_enum, lighten_color, palette\n",
    "from dsgrid.model import ComponentType, LoadModelComponent, LoadModel\n",
    "\n",
    "enumdata_folder = Path(enumdata_folder)\n",
    "\n",
    "from ntbkhelp import OptionPresenter\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def make_dir(p, prompt=True):\n",
    "    if p.exists():\n",
    "        return\n",
    "    if prompt:\n",
    "        input_str = input(f\"{p!r} does not exist. Would you like to create it? [Y/n] \")\n",
    "        if not (input_str[0].lower() == \"y\"):\n",
    "            return\n",
    "    if not p.parent.exists():\n",
    "        make_dir(p.parent, prompt=prompt)\n",
    "    p.mkdir()\n",
    "    print(f\"Created {p!r}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd04669",
   "metadata": {},
   "source": [
    "## Choose data location\n",
    "\n",
    "Review the choices in the first cell, select the path you want to use in the second cell, and run both cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publicly available\n",
    "#dsgrid_hsds_base_path = \"/nrel/dsgrid-2018-efs\"               # More performant, uses h5pyd -- Not yet working\n",
    "dsgrid_oedi_base_path = \"s3://oedi-data-lake/dsgrid-2018-efs\" # Uses h5py\n",
    "# Internal to NREL\n",
    "dsgrid_nrel_base_path_windows = Path(\"//nrelnas01/PLEXOS/Projects/Load/dsgrid_v0.2.0/\")\n",
    "dsgrid_nrel_base_path_mac = Path(\"/Volumes/PLEXOS/Projects/Load/dsgrid_v0.2.0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908da519",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsgrid_base_path = dsgrid_oedi_base_path\n",
    "\n",
    "is_hsds = str(dsgrid_base_path).startswith(\"/nrel/\")\n",
    "if is_hsds:\n",
    "    import h5pyd\n",
    "is_s3 = str(dsgrid_base_path).startswith(\"s3://\")\n",
    "if is_s3:\n",
    "    import s3fs\n",
    "    s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312a3de",
   "metadata": {},
   "source": [
    "## Specify a local directory for any outputs\n",
    "\n",
    "Review and edit the specified path. (The default option should be available for most everyone, but feel to change as you see fit.) Review the additional options in the first cell. Then run this section\n",
    "\n",
    "⚠️ **WARNING** ⚠️ Setting overwrite to True will cause some code to run slower, probably unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a local directory for any outputs\n",
    "output_dir = Path.home() / \"Documents\" / \"dsgrid-legacy-efs\"\n",
    "\n",
    "# Plotting code will always overwrite graphics (e.g., \n",
    "# .png files) on disk\n",
    "# \n",
    "# If you also want to re-process dsgrid model mappings \n",
    "# whenever you run a cell containing such work, \n",
    "# set overwrite to True\n",
    "overwrite = False        # Choices: False, True\n",
    "\n",
    "# Specify logging level\n",
    "log_level = logging.INFO # Choices: logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=log_level)\n",
    "    \n",
    "make_dir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9e346",
   "metadata": {},
   "source": [
    "## Helper functions and data for setting up dsgrid models\n",
    "\n",
    "Run this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_components(datadir,component_type,tuple_list):\n",
    "    is_hsds = str(datadir).startswith(\"/nrel/\")\n",
    "    if is_hsds:\n",
    "        with h5pyd.Folder(dsgrid_dataset_path) as d:\n",
    "            files = list(d)\n",
    "    is_s3 = str(datadir).startswith(\"s3://\")\n",
    "    if is_s3:\n",
    "        files = [p.split(\"/\")[-1] for p in s3.glob(f\"{dsgrid_dataset_path}/*.dsg\")]\n",
    "    \n",
    "    result = []\n",
    "    for name, color, filepath in tuple_list:\n",
    "        if is_hsds or is_s3:\n",
    "            if not filepath in files:\n",
    "                logger.info(f'No {name} component in {datadir}')\n",
    "                continue\n",
    "        elif not (datadir / filepath).exists():\n",
    "            logger.info(f'No {name} component in {datadir}')\n",
    "            continue\n",
    "        result.append(LoadModelComponent(name,component_type=component_type,color=color))\n",
    "        result[-1].load_datafile(\n",
    "            f\"{datadir}/{filepath}\" if (is_hsds or is_s3) else datadir / filepath)\n",
    "    return result\n",
    "\n",
    "# Bottom-Up\n",
    "bottomup_components_list = [\n",
    "    ('Residential','#F7A11A','residential.dsg'),\n",
    "    ('Commercial','#5D9732','commercial.dsg'),\n",
    "    ('Industrial','#D9531E','industrial.dsg')]\n",
    "\n",
    "# Gaps\n",
    "color_fade_frac = 0.3\n",
    "gap_components_list = [\n",
    "    ('Residential Gaps',lighten_color(bottomup_components_list[0][1],color_fade_frac),'residential_gaps.dsg'),\n",
    "    ('Commercial Gaps',lighten_color(bottomup_components_list[1][1],color_fade_frac),'commercial_gaps.dsg'),\n",
    "    ('Industrial Gaps',lighten_color(bottomup_components_list[2][1],color_fade_frac),'industrial_gaps.dsg'),\n",
    "    ('Transportation Gaps',lighten_color(\"#0079C2\",color_fade_frac),'trans_rail_hourly.dsg'),\n",
    "    ('Municipal Water','#00CCCC','municipal_water.dsg'),\n",
    "    ('Outdoor Lighting','#FFFF33','outdoor_lighting.dsg')]\n",
    "\n",
    "# DG\n",
    "dg_components_list = [\n",
    "    ('CHP and Thermal DG','#99004D','chp_dg.dsg'),\n",
    "    ('Distributed PV','#CD9B1D','distributedpv_sectoral.dsg'),\n",
    "    ('Distributed Generation','#99004D','distributed_generation.dsg')]\n",
    "\n",
    "# Derived\n",
    "derived_components_list = [\n",
    "    ('Loss Model','#9A9A9A','loss_model.dsg'),\n",
    "    ('Hourly Residuals','#632E86','hourly_residuals.dsg')]\n",
    "\n",
    "# Top-Down\n",
    "topdown_components_list = [\n",
    "    ('Top-Down Hourly',None,'historical_hourly_load.dsg'),\n",
    "    ('Top-Down Annual Energy',None,'eia_annual_energy_by_sector.dsg')]\n",
    "\n",
    "# informational list of components which use sector_id to differentiate between res, com, ind\n",
    "# other components either use sector_id to represent subsectors or have a single sector_id\n",
    "by_sector_components = [\n",
    "    (ComponentType(ComponentType.TOPDOWN),'Top-Down Annual Energy'),\n",
    "    (ComponentType(ComponentType.DG),'CHP and Thermal DG'),\n",
    "    (ComponentType(ComponentType.DG),'Distributed PV')\n",
    "]\n",
    "\n",
    "def get_model(model_dir):\n",
    "    bottomup_components = load_components(model_dir,ComponentType.BOTTOMUP,bottomup_components_list)\n",
    "    gap_components = load_components(model_dir,ComponentType.GAP,gap_components_list)\n",
    "    dg_components = load_components(model_dir,ComponentType.DG,dg_components_list)\n",
    "    derived_components = load_components(model_dir,ComponentType.DERIVED,derived_components_list)\n",
    "    topdown_components = load_components(model_dir,ComponentType.TOPDOWN,topdown_components_list)\n",
    "    return LoadModel.create(bottomup_components + gap_components + dg_components + derived_components + topdown_components)\n",
    "\n",
    "def downselect_model(model,component_keys):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : dsgrid.LoadModel\n",
    "    component_keys : list of keys in model.components\n",
    "        List of component keys in model that are to be KEPT.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dsgrid.LoadModel\n",
    "        Same object as model. Upon return any components whose keys are not in \n",
    "        component_keys will have been deleted.\n",
    "    \"\"\"\n",
    "    to_delete = []\n",
    "    for key in model.components:\n",
    "        if key not in component_keys:\n",
    "            to_delete.append(key)\n",
    "    for key in to_delete:\n",
    "        del model.components[key]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper plotting functions\n",
    "\n",
    "from ntbkhelp import (model_tz, get_dim_order, add_temporal_category, clean_name, \n",
    "                      MatplotlibAxisPosition, enduse_color_map, component_plot, \n",
    "                      week_names, prep_for_seasonal_subplots)\n",
    "\n",
    "# Per https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/customize-dates-matplotlib-plots-python/\n",
    "# this is supposed to ...\n",
    "# \"Handle date time conversions between pandas and matplotlib\"\n",
    "# ... but it doesn't seem to be helping enough\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "\n",
    "def seasonal_example_weeks_sectors(model, geo_id=None, plots_dir=None, show=False):\n",
    "    \"\"\"\n",
    "    dsgrid Model Documentation Figure 19\n",
    "    \n",
    "    Note that this version of the code expects a single geography, either because\n",
    "    there is only one geography in the dataset (e.g., for CONUS), or because geo_id\n",
    "    is specified. However, the code was adapted from a different location in which\n",
    "    geography was looped over and much of that infrastructure (i.e., \n",
    "    groupby(['geography'])) remains intact. If you would like to do something similar, \n",
    "    at a minimum you will want to change the figure filename to include the value of \n",
    "    geo, e.g., f\"seasonal_example_weeks_sectors_{geo}.png\".\n",
    "    \"\"\"\n",
    "    unit_name = 'GW'\n",
    "    unit_scale = 1.0E-3\n",
    "    font_size = 14\n",
    "    figsize = (8,9.5)\n",
    "    n_leg_cols = 3\n",
    "    leg_pos = 8 # 5\n",
    "    axis_position_kwargs = {\n",
    "        'ax_lowleft_pos': '0.11,0.16',\n",
    "        'ax_upright_pos': '0.98,0.98'\n",
    "    }\n",
    "    legend_kwargs = {\n",
    "        'labelspacing': 0.01,\n",
    "        'handleheight': 1.2,\n",
    "        'handlelength': 1.2,\n",
    "        'ncol': n_leg_cols,\n",
    "        'fontsize': font_size\n",
    "    }\n",
    "    plt.style.use(['ggplot'])\n",
    "\n",
    "    def transform_label(label):\n",
    "        label = label.replace('Residential','Res.')\n",
    "        label = label.replace('Commercial','Com.')\n",
    "        label = label.replace('Industrial','Ind.')\n",
    "        label = label.replace('Transportation','Trans.')\n",
    "        if (not label.endswith('Gaps')) and (label.endswith('.')):\n",
    "            label += ' Sector'\n",
    "        return label\n",
    "    \n",
    "    component_order = [\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Residential'),\n",
    "        (ComponentType(ComponentType.GAP),'Residential Gaps'),\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Commercial'),\n",
    "        (ComponentType(ComponentType.GAP),'Commercial Gaps'),\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Industrial'),\n",
    "        (ComponentType(ComponentType.GAP),'Industrial Gaps'),\n",
    "        (ComponentType(ComponentType.GAP),'Transportation Gaps'),\n",
    "        (ComponentType(ComponentType.GAP),'Municipal Water'),\n",
    "        (ComponentType(ComponentType.GAP),'Outdoor Lighting'),\n",
    "        (ComponentType(ComponentType.DERIVED),'Loss Model')]\n",
    "    \n",
    "    def get_timeseries_by_geography(component, grouped=True):\n",
    "        result = component.get_datatable(sort=False,verify_integrity=False).data\n",
    "        if geo_id is not None:\n",
    "            try:\n",
    "                result = result.xs(geo_id, level=\"geography\", drop_level=False)\n",
    "            except:\n",
    "                logger.info(f\"There is no data for {geo_id} in {Path(component.datafile.filepath).name}\")\n",
    "                return None\n",
    "        result = result.groupby(['geography','time']).sum()\n",
    "        if grouped:\n",
    "            result = result.groupby(['geography'])\n",
    "        return result\n",
    "\n",
    "    def add_component_data(accumulator, component):\n",
    "        ts_by_geo = get_timeseries_by_geography(component,grouped=False)\n",
    "        \n",
    "        if ts_by_geo is not None:\n",
    "            if accumulator is None:\n",
    "                accumulator = ts_by_geo\n",
    "            else:\n",
    "                accumulator = accumulator.add(ts_by_geo,fill_value=None)\n",
    "        return accumulator\n",
    "    \n",
    "    top_down_hourly = get_timeseries_by_geography(\n",
    "        model.components[(ComponentType(ComponentType.TOPDOWN),'Top-Down Hourly')],\n",
    "        grouped = False)\n",
    "        \n",
    "    dg_hourly = None\n",
    "    for key, component in model.components.items():\n",
    "        if key[0] == ComponentType(ComponentType.DG):\n",
    "            dg_hourly = add_component_data(dg_hourly,component)\n",
    "    dg_hourly = dg_hourly.groupby(['geography','time']).sum().groupby('geography')\n",
    "\n",
    "    colors = []; columns = []; grouped_data = {}\n",
    "    for key in component_order:\n",
    "        component = model.components[key]\n",
    "        tmp = get_timeseries_by_geography(component, grouped=True)\n",
    "        if tmp is not None:\n",
    "            colors.append(component.color)\n",
    "            columns.append(component.name)\n",
    "            grouped_data[key] = tmp\n",
    "\n",
    "    original_figsize = tuple(matplotlib.rcParams['figure.figsize'])\n",
    "    matplotlib.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "    axis_position_styler = MatplotlibAxisPosition()\n",
    "\n",
    "    for geo, ts in top_down_hourly.groupby('geography'):\n",
    "        if geo_id is not None:\n",
    "            assert geo == geo_id\n",
    "        max_ylim = 0.0\n",
    "        ts.index = ts.index.droplevel()\n",
    "        dg_ts = dg_hourly.get_group(geo)\n",
    "        dg_ts.index = dg_ts.index.droplevel()\n",
    "        ts2 = ts + dg_ts\n",
    "\n",
    "        # gather all ingredients\n",
    "        data = []; dropped = []\n",
    "        for i, key in enumerate(component_order):\n",
    "            try:\n",
    "                s = grouped_data[key].get_group(geo)\n",
    "                s.index = s.index.droplevel()\n",
    "                data.append(s)\n",
    "            except: \n",
    "                dropped.append(i)\n",
    "        df = pd.concat(data,axis=1)\n",
    "        df.columns = [col for i, col in enumerate(columns) if i not in dropped]\n",
    "        df = prep_for_seasonal_subplots(df)\n",
    "\n",
    "        ts.name = 'Historical Hourly'\n",
    "        ts = prep_for_seasonal_subplots(pd.DataFrame(ts))\n",
    "        ts2.name = 'Hist. Hourly + DG'\n",
    "        ts2 = prep_for_seasonal_subplots(pd.DataFrame(ts2))\n",
    "\n",
    "        fig, axx = plt.subplots(4,1)\n",
    "        first = True\n",
    "        date_formatter = matplotlib.dates.DateFormatter('%m/%d', tz=model_tz)\n",
    "        date_locator = matplotlib.dates.DayLocator(tz=model_tz)\n",
    "        for i, week in enumerate(week_names):\n",
    "            to_plot = df[df.Season == week]\n",
    "            del to_plot['Season']\n",
    "            to_plot = to_plot * unit_scale\n",
    "            to_plot_colors = [color for i, color in enumerate(colors) if i not in dropped]\n",
    "            to_plot.plot(ax=axx[i],\n",
    "                         kind='area',\n",
    "                         color=to_plot_colors,\n",
    "                         legend=False)\n",
    "\n",
    "            ts_to_plot = ts[ts.Season == week]\n",
    "            del ts_to_plot['Season']\n",
    "            ts2_to_plot = ts2[ts2.Season == week]\n",
    "            del ts2_to_plot['Season']\n",
    "            ts_to_plot = pd.concat([ts_to_plot,ts2_to_plot],axis=1)\n",
    "            ts_to_plot = ts_to_plot * unit_scale\n",
    "            ts_to_plot.plot(ax=axx[i],\n",
    "                            kind='line',\n",
    "                            style=['k--','k-'],\n",
    "                            legend=False)\n",
    "\n",
    "            if first:\n",
    "                handles, labels = axx[i].get_legend_handles_labels()\n",
    "                first = False\n",
    "\n",
    "            axx[i].yaxis.label.set_size(font_size+2)\n",
    "            axx[i].tick_params(axis='y',labelsize=font_size,colors='k')\n",
    "            axx[i].set_ylabel(week + ' ({})'.format(unit_name),color='k')\n",
    "            axx[i].set_xlabel('')\n",
    "            # This used to work and would be cleaner ... Originally did not require the locator.\n",
    "            #axx[i].get_xaxis().set_major_locator(date_locator)\n",
    "            #axx[i].get_xaxis().set_major_formatter(date_formatter)\n",
    "            axx[i].tick_params(axis='x',labelsize=font_size-4,colors='k')\n",
    "            axx[i].autoscale(axis='x',tight=True)\n",
    "            if axx[i].get_ylim()[1] > max_ylim:\n",
    "                max_ylim = axx[i].get_ylim()[1]\n",
    "            if ts_to_plot.max().max() > max_ylim:\n",
    "                max_val = ts_to_plot.max().max()\n",
    "                ticks = axx[i].get_yticks(minor=False)\n",
    "                delta_y = (ticks[1] - ticks[0]) / 10.0\n",
    "                tmp = ticks[-1]\n",
    "                while tmp < max_val:\n",
    "                    tmp += delta_y\n",
    "                max_ylim = tmp\n",
    "\n",
    "        for i, week in enumerate(week_names):\n",
    "            axx[i].set_ylim((0.0,max_ylim))\n",
    "        axis_position_styler.postprocess(fig=fig,ax=axx,**axis_position_kwargs)\n",
    "\n",
    "        legend = plt.figlegend(handles[::-1],[transform_label(label) for label in labels[::-1]],leg_pos,**legend_kwargs)\n",
    "        legend.draw_frame(False)\n",
    "\n",
    "        if plots_dir is not None:\n",
    "            fig.savefig(plots_dir / \"seasonal_example_weeks_sectors.png\", dpi=1200)\n",
    "        if not show:\n",
    "            plt.close(fig)\n",
    "\n",
    "    matplotlib.rcParams['figure.figsize'] = original_figsize\n",
    "    \n",
    "\n",
    "def seasonal_example_weeks_residuals(model, geo_id=None, plots_dir=None, show=False):\n",
    "    \"\"\"\n",
    "    dsgrid Model Documentation Figure 20\n",
    "    \n",
    "    Note that this version of the code expects a single geography, either because\n",
    "    there is only one geography in the dataset (e.g., for CONUS), or because geo_id\n",
    "    is specified. However, the code was adapted from a different location in which\n",
    "    geography was looped over and much of that infrastructure (i.e., \n",
    "    groupby(['geography'])) remains intact. If you would like to do something similar, \n",
    "    at a minimum you will want to change the figure filename to include the value of \n",
    "    geo, e.g., f\"seasonal_example_weeks_residuals_{geo}.png\".\n",
    "    \"\"\"\n",
    "    fade = 0.25\n",
    "    columns = ['DG-CHP','DG-PV','Modeled - DG - Overeage','Underage','T&D Losses','Overage']\n",
    "\n",
    "    unit_name = 'GW'\n",
    "    unit_scale = 1.0E-3\n",
    "    font_size = 14\n",
    "    figsize = (8,9.5)\n",
    "    n_leg_cols = 2\n",
    "    leg_pos = 8 # 5\n",
    "    #axis_position_kwargs = {\n",
    "    #    'ax_lowleft_pos': '0.08,0.05',\n",
    "    #    'ax_upright_pos': '0.7,0.95'\n",
    "    #}\n",
    "    axis_position_kwargs = {\n",
    "        'ax_lowleft_pos': '0.11,0.16',\n",
    "        'ax_upright_pos': '0.98,0.98'\n",
    "    }\n",
    "    legend_kwargs = {\n",
    "        'labelspacing': 0.01,\n",
    "        'handleheight': 1.2,\n",
    "        'handlelength': 1.2,\n",
    "        'ncol': n_leg_cols,\n",
    "        'fontsize': font_size\n",
    "    }     \n",
    "    \n",
    "    model_components = [\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Residential'),\n",
    "        (ComponentType(ComponentType.GAP),'Residential Gaps'),\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Commercial'),\n",
    "        (ComponentType(ComponentType.GAP),'Commercial Gaps'),\n",
    "        (ComponentType(ComponentType.BOTTOMUP),'Industrial'),\n",
    "        (ComponentType(ComponentType.GAP),'Industrial Gaps'),\n",
    "        (ComponentType(ComponentType.GAP),'Transportation Gaps'),\n",
    "        (ComponentType(ComponentType.GAP),'Municipal Water'),\n",
    "        (ComponentType(ComponentType.GAP),'Outdoor Lighting')]\n",
    "\n",
    "    loss_component = (ComponentType(ComponentType.DERIVED),'Loss Model')\n",
    "\n",
    "    dg_components = [\n",
    "        (ComponentType(ComponentType.DG),'CHP and Thermal DG'),\n",
    "        (ComponentType(ComponentType.DG),'Distributed PV')]\n",
    "    resid_component = (ComponentType(ComponentType.DERIVED),'Hourly Residuals')\n",
    "    \n",
    "    def get_timeseries_by_geography(component, grouped=True):\n",
    "        result = component.get_datatable(sort=False,verify_integrity=False).data\n",
    "        if geo_id is not None:\n",
    "            try:\n",
    "                result = result.xs(geo_id, level=\"geography\", drop_level=False)\n",
    "            except:\n",
    "                logger.info(f\"There is no data for {geo_id} in {Path(component.datafile.filepath).name}\")\n",
    "                return None\n",
    "        result = result.groupby(['geography','time']).sum()\n",
    "        if grouped:\n",
    "            result = result.groupby(['geography'])\n",
    "        return result\n",
    "    \n",
    "    def add_component_data(accumulator, component):\n",
    "        ts_by_geo = get_timeseries_by_geography(component,grouped=False)\n",
    "        \n",
    "        if ts_by_geo is not None:\n",
    "            if accumulator is None:\n",
    "                accumulator = ts_by_geo\n",
    "            else:\n",
    "                accumulator = accumulator.add(ts_by_geo,fill_value=0.0)\n",
    "        return accumulator\n",
    "\n",
    "    # calculate modeled portion\n",
    "    modeled = None\n",
    "    for key in model_components:\n",
    "        modeled = add_component_data(modeled, model[key])\n",
    "    modeled_grouped = modeled.groupby('geography')\n",
    "    \n",
    "    # pull and group hourly timeseries, losses, dg - resid\n",
    "    top_down_hourly = get_timeseries_by_geography(\n",
    "        model.components[(ComponentType(ComponentType.TOPDOWN),'Top-Down Hourly')], \n",
    "        grouped=False)\n",
    "\n",
    "    loss = get_timeseries_by_geography(model.components[loss_component])\n",
    "    loss_color = model.components[loss_component].color\n",
    "\n",
    "    dg = []\n",
    "    dg_color = []\n",
    "    for dg_component in dg_components:\n",
    "        tmp = get_timeseries_by_geography(model.components[dg_component])\n",
    "        if tmp is not None:\n",
    "            dg.append(tmp)\n",
    "            dg_color.append(model.components[dg_component].color)\n",
    "\n",
    "    resid = get_timeseries_by_geography(model.components[resid_component])\n",
    "    resid_color = model.components[resid_component].color\n",
    "    \n",
    "    colors = dg_color + [lighten_color('#F05A28',fade), lighten_color(resid_color,fade), loss_color, lighten_color(resid_color,fade)]\n",
    "    \n",
    "    original_figsize = tuple(matplotlib.rcParams['figure.figsize'])\n",
    "    matplotlib.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "    axis_position_styler = MatplotlibAxisPosition()\n",
    "\n",
    "    def get_series(grouped_data,geo):\n",
    "        s = grouped_data.get_group(geo)\n",
    "        s.index = s.index.droplevel()\n",
    "        return s\n",
    "\n",
    "    for geo, ts in top_down_hourly.groupby('geography'):\n",
    "        max_ylim = 0.0\n",
    "        ts.index = ts.index.droplevel()\n",
    "\n",
    "        # gather all ingredients\n",
    "        data = []; dropped = []\n",
    "\n",
    "        # dg -- 0, 1\n",
    "        dg_total = None\n",
    "        for i, dg_type in enumerate(dg):\n",
    "            candidate = pd.Series(dtype=float)\n",
    "            try:\n",
    "                candidate = get_series(dg_type,geo)\n",
    "            except: pass\n",
    "            if candidate.empty:\n",
    "                dropped.append(i)\n",
    "            else:\n",
    "                data.append(candidate)\n",
    "                if dg_total is None:\n",
    "                    dg_total = copy.deepcopy(data[-1])\n",
    "                else:\n",
    "                    dg_total = dg_total.add(data[-1],fill_value=0.0)\n",
    "\n",
    "        # get and split residuals\n",
    "        resid_s = get_series(resid,geo)\n",
    "        neg_resid = resid_s[resid_s.values < 0.0]; pos_resid = resid_s[resid_s.values >= 0.0]\n",
    "\n",
    "        # modeled - dg - neg_resid -- 2\n",
    "        modeled_minus_dg = get_series(modeled_grouped,geo).subtract(-neg_resid,fill_value=0.0)\n",
    "        if dg_total is not None:\n",
    "            modeled_minus_dg = modeled_minus_dg.subtract(dg_total,fill_value=0.0)\n",
    "        data.append(modeled_minus_dg)\n",
    "\n",
    "        # pos_resid -- 3\n",
    "        if pos_resid.empty:\n",
    "            dropped.append(3)\n",
    "        else:\n",
    "            data.append(pos_resid)\n",
    "\n",
    "        # losses -- 4\n",
    "        data.append(get_series(loss,geo))\n",
    "\n",
    "        # neg_resid -- 5\n",
    "        if neg_resid.empty:\n",
    "            dropped.append(5)\n",
    "        else:\n",
    "            data.append(-neg_resid)\n",
    "\n",
    "        df = pd.concat(data,axis=1)\n",
    "        #df.fillna(value=0.0,inplace=True)\n",
    "        df.columns = [col for i, col in enumerate(columns) if i not in dropped]\n",
    "        clrs = [color for i, color in enumerate(colors) if i not in dropped]\n",
    "        df = prep_for_seasonal_subplots(df)\n",
    "\n",
    "        # print(pd.concat([dg,get_series(modeled_grouped,geo),modeled_minus_dg],axis=1))\n",
    "\n",
    "        if dg_total is not None:\n",
    "            ts = ts.add(dg_total,fill_value=0.0)\n",
    "        ts.name = 'Hist. Hourly + DG'\n",
    "        ts = prep_for_seasonal_subplots(pd.DataFrame(ts))\n",
    "\n",
    "        fig, axx = plt.subplots(4,1)\n",
    "        first = True\n",
    "        for i, week in enumerate(week_names):\n",
    "            to_plot = df[df.Season == week]\n",
    "            del to_plot['Season']\n",
    "            to_plot = to_plot * unit_scale\n",
    "            to_plot.plot(ax=axx[i],\n",
    "                         kind='area',\n",
    "                         color=clrs,\n",
    "                         legend=False)\n",
    "\n",
    "            ts_to_plot = ts[ts.Season == week]\n",
    "            del ts_to_plot['Season']\n",
    "            ts_to_plot = ts_to_plot * unit_scale\n",
    "            ts_to_plot.plot(ax=axx[i],\n",
    "                            kind='line',\n",
    "                            color='k',\n",
    "                            legend=False)\n",
    "\n",
    "            if first:\n",
    "                handles, labels = axx[i].get_legend_handles_labels()\n",
    "                first = False\n",
    "\n",
    "            axx[i].yaxis.label.set_size(font_size)\n",
    "            axx[i].tick_params(axis='y',labelsize=font_size,colors='k')\n",
    "            axx[i].set_ylabel(week + ' ({})'.format(unit_name),color='k')\n",
    "            axx[i].set_xlabel('')\n",
    "            # This used to work and would be cleaner ...\n",
    "            #axx[i].get_xaxis().set_major_formatter(matplotlib.dates.DateFormatter('%m/%d'))\n",
    "            axx[i].tick_params(axis='x',labelsize=font_size-4,colors='k')\n",
    "            axx[i].autoscale(axis='x',tight=True)\n",
    "            if axx[i].get_ylim()[1] > max_ylim:\n",
    "                max_ylim = axx[i].get_ylim()[1]\n",
    "            if ts_to_plot.max().max() > max_ylim:\n",
    "                max_val = ts_to_plot.max().max()\n",
    "                ticks = axx[i].get_yticks(minor=False)\n",
    "                delta_y = (ticks[1] - ticks[0]) / 10.0\n",
    "                tmp = ticks[-1]\n",
    "                while tmp < max_val:\n",
    "                    tmp += delta_y\n",
    "                max_ylim = tmp\n",
    "\n",
    "        for i, week in enumerate(week_names):\n",
    "            axx[i].set_ylim((0.0,max_ylim))\n",
    "        axis_position_styler.postprocess(fig=fig,ax=axx,**axis_position_kwargs)\n",
    "\n",
    "        handles = handles[::-1]; labels = labels[::-1]\n",
    "\n",
    "        legend = plt.figlegend(handles,labels,leg_pos,**legend_kwargs)\n",
    "        legend.draw_frame(False)\n",
    "\n",
    "        if plots_dir is not None:\n",
    "            fig.savefig(plots_dir / \"seasonal_example_weeks_residuals.png\",dpi=1200)\n",
    "        if not show:\n",
    "            plt.close(fig)\n",
    "\n",
    "    matplotlib.rcParams['figure.figsize'] = original_figsize\n",
    "\n",
    "    \n",
    "def seasonal_diurnal_profiles(model, component_id, geo_id=None, plots_dir=None, show=False, \n",
    "                              subsector_plot=True, enduse_plot=True, enduse_by_subsector_plots=True,\n",
    "                              area_plots=True, line_plots=True):\n",
    "    \"\"\"\n",
    "    dsgrid Model Documentation Figures 23, 24, 25\n",
    "    \"\"\"\n",
    "    font_size = 12\n",
    "    n_leg_cols = 1\n",
    "    max_subsectors = 15\n",
    "    \n",
    "    plot_kwargs = dict(\n",
    "        font_size = font_size,\n",
    "        figsize = (6.5,6.5),\n",
    "        n_leg_cols = n_leg_cols,\n",
    "        leg_pos = 5,\n",
    "        axis_position_kwargs = {\n",
    "            'ax_lowleft_pos': '0.115,0.075',\n",
    "            'ax_upright_pos': '0.675,0.95'\n",
    "        },\n",
    "        legend_kwargs = {\n",
    "            'labelspacing': 0.02,\n",
    "            'handleheight': 1.2,\n",
    "            'handlelength': 1.2,\n",
    "            'ncol': n_leg_cols,\n",
    "            'fontsize': font_size-1\n",
    "        },\n",
    "        subplots_adjust_kwargs = {\n",
    "            'hspace': 0.001,\n",
    "            'wspace': 0.001\n",
    "        },\n",
    "        max_subsectors = 15)\n",
    "    \n",
    "    plt.style.use(['ggplot'])\n",
    "\n",
    "    # Get the data to plot\n",
    "    data = model[component_id].get_datatable(sort=False,verify_integrity=False).data\n",
    "    if geo_id is not None:\n",
    "        logger.info(f\"Selecting {geo_id} data from {component_id}\")\n",
    "        data = data.xs(geo_id, level=\"geography\", drop_level=False)\n",
    "    enduses = get_dim_order(data,'enduse'); enduse_enum = model[component_id].datafile.enduse_enum\n",
    "    logger.info(f\"Plotting profiles for {component_id} with enduses {enduses}\")\n",
    "    subsectors = get_dim_order(data,'sector'); sector_enum = model[component_id].datafile.sector_enum\n",
    "    geographies = get_dim_order(data,'geography'); geo_enum = model[component_id].datafile.geo_enum\n",
    "\n",
    "    # color palettes\n",
    "    enduse_colors = palette(model[component_id].color,len(enduses))\n",
    "    subsector_colors = palette(model[component_id].color,len(subsectors))\n",
    "\n",
    "    # add temporal information -- season, weekday/weekend, hour 1 to 24\n",
    "    data.name = 'value'\n",
    "    data = data.reset_index()\n",
    "    season_map = pd.read_csv(enumdata_folder / 'hourly2012_to_seasons.csv')\n",
    "    daytype_map = pd.read_csv(enumdata_folder / 'hourly2012_to_daytypes.csv')\n",
    "    hours_map = pd.read_csv(enumdata_folder / 'hourly2012_to_hours.csv')\n",
    "    data = add_temporal_category(data,season_map,'season')\n",
    "    data = add_temporal_category(data,daytype_map,'day_type')\n",
    "    data = add_temporal_category(data,hours_map,'hour')\n",
    "    \n",
    "    tmp = data.set_index(['sector','geography','enduse','time','season','day_type','hour'])\n",
    "    tmp = pd.Series(tmp['value'])\n",
    "\n",
    "    # refresh just for this dataset\n",
    "    enduses = get_dim_order(tmp,'enduse')\n",
    "    subsectors = get_dim_order(tmp,'sector')\n",
    "    enduse_colors = []; tmp = palette(model[component_id].color,len(enduses))\n",
    "    for i, enduse in enumerate(enduses):\n",
    "        if enduse in enduse_color_map:\n",
    "            enduse_colors.append(enduse_color_map[enduse])\n",
    "        else:\n",
    "            enduse_colors.append(tmp[i])\n",
    "    subsector_colors = palette(model[component_id].color,len(subsectors))\n",
    "    \n",
    "    component_prefix = component_id[1].lower().replace(' ','-')\n",
    "\n",
    "    if subsector_plot:\n",
    "        # plot by subsector\n",
    "        logger.info(\"Prepping subsector profiles ...\")\n",
    "        # ... the .sum portion of this step is very slow for detailed components\n",
    "        logger.info(\"... aggregating ...\")\n",
    "        to_plot = data.groupby(['time','season','day_type','hour','sector']).sum().reset_index()\n",
    "        logger.info(\"... pivoting\")\n",
    "        to_plot = to_plot.pivot_table(values='value',\n",
    "                                      index=['season','day_type','hour'],\n",
    "                                      columns='sector',\n",
    "                                      aggfunc=np.mean)\n",
    "        to_plot.columns = [col for col in to_plot.columns]\n",
    "        to_plot = to_plot[subsectors]      \n",
    "\n",
    "        if len(subsectors) > max_subsectors:\n",
    "            to_collapse = subsectors[max_subsectors:]\n",
    "            to_plot['Other'] = to_plot[to_collapse].sum(axis=1)\n",
    "            for col in to_collapse:\n",
    "                del to_plot[col]\n",
    "            subsector_colors = palette(model[component_id].color,max_subsectors+1)\n",
    "\n",
    "        logger.info(\"Making subsector plots\")\n",
    "        component_plot(to_plot,subsector_colors,sector_enum,\n",
    "                       plots_dir,\n",
    "                       f'{component_prefix}-subsectors-area.png' if area_plots else None, \n",
    "                       f'{component_prefix}-subsectors-line.png' if line_plots else None, \n",
    "                       show=show, **plot_kwargs)\n",
    "\n",
    "    # if multiple end-uses\n",
    "    if len(enduses) > 1:\n",
    "        if enduse_plot:\n",
    "            # plot by enduse\n",
    "            logger.info(\"Prepping enduse profiles ...\")\n",
    "            # ... the .sum portion of this step is very slow for detailed components\n",
    "            logger.info(\"... aggregating ...\")\n",
    "            to_plot = data.groupby(['time','season','day_type','hour','enduse']).sum().reset_index()\n",
    "            logger.info(\"... pivoting\")\n",
    "            to_plot = to_plot.pivot_table(values='value',\n",
    "                                          index=['season','day_type','hour'],\n",
    "                                          columns='enduse',\n",
    "                                          aggfunc=np.mean)\n",
    "            to_plot.columns = [col for col in to_plot.columns]\n",
    "            to_plot = to_plot[enduses]\n",
    "            logger.info(\"Making enduse plots\")\n",
    "            component_plot(to_plot,enduse_colors,enduse_enum,\n",
    "                           plots_dir,\n",
    "                           f'{component_prefix}-enduses-area.png' if area_plots else None,\n",
    "                           f'{component_prefix}-enduses-line.png' if line_plots else None,\n",
    "                           show=show, **plot_kwargs)\n",
    "\n",
    "        # if multiple subsectors and end-uses\n",
    "        if (len(subsectors) > 1) and (len(subsectors) < 30) and enduse_by_subsector_plots:\n",
    "            # for each subsector\n",
    "            for subsector in subsectors:\n",
    "                # plot by enduse\n",
    "                logger.info(f\"Prepping {subsector} enduse profiles ...\")\n",
    "                # ... the .sum portion of this step is very slow for detailed components\n",
    "                logger.info(\"... aggregating ...\")\n",
    "                to_plot = data[data.sector == subsector].groupby(['time','season','day_type','hour','enduse']).sum().reset_index()\n",
    "                logger.info(\"... pivoting\")\n",
    "                to_plot = to_plot.pivot_table(values='value',\n",
    "                                              index=['season','day_type','hour'],\n",
    "                                              columns='enduse',\n",
    "                                              aggfunc=np.mean)\n",
    "                to_plot.columns = [col for col in to_plot.columns]\n",
    "                to_plot = to_plot[enduses]\n",
    "                subsector_prefix = clean_name(sector_enum.get_name(subsector)).lower().replace(' ', '-')\n",
    "                logger.info(f\"Making {subsector} enduse plots\")\n",
    "                component_plot(to_plot,enduse_colors,enduse_enum,\n",
    "                               plots_dir,\n",
    "                               f'{component_prefix}-{subsector_prefix}-enduses-area.png' if area_plots else None,\n",
    "                               f'{component_prefix}-{subsector_prefix}-enduses-line.png' if line_plots else None,\n",
    "                               show=show, **plot_kwargs)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729dda60",
   "metadata": {},
   "source": [
    "## Choose analysis type\n",
    "\n",
    "Select the analysis_type in the second cell. Then run all cells in this section. If you want to change your analysis_type choice later, just make the change and re-run the second and third cells.\n",
    "\n",
    "AnalysisType.Residuals enables plots:\n",
    "\n",
    "- seasonal_example_weeks_sectors (dsgrid Model Documentation Figure 19)\n",
    "- seasonal_example_weeks_residuals (dsgrid Model Documentation Figure 20)\n",
    "\n",
    "AnalysisType.Modeled enables plots:\n",
    "\n",
    "- seasonal_diurnal_profiles (dsgrid Model Documentation Figures 23, 24, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisType(Enum):\n",
    "    Residuals = auto() # modeled components, historical data, and residuals\n",
    "    Modeled = auto()   # only dsgrid-modeled \"bottom-up\" and \"gap\" components\n",
    "\n",
    "if is_hsds or is_s3:\n",
    "    all_components_model_path = f\"{dsgrid_base_path}/state_hourly_residuals\"\n",
    "    bottom_up_components_model_path = f\"{dsgrid_base_path}/dsgrid_site_energy_state_hourly\"\n",
    "else:\n",
    "    all_components_model_path = dsgrid_base_path / \"products\" / \"state_hourly_residuals\"\n",
    "    bottom_up_components_model_path = dsgrid_base_path / \"products\" / \"dsgrid_site_energy_state_hourly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a621864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which version of the dsgrid data you want to examine\n",
    "analysis_type = AnalysisType.Residuals # Choices: AnalysisType.Residuals, AnalysisType.Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_type = ensure_enum(AnalysisType, analysis_type)\n",
    "dsgrid_dataset_path = all_components_model_path if analysis_type == AnalysisType.Residuals else bottom_up_components_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4602bb",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e2b72",
   "metadata": {},
   "source": [
    "## Contiguous United States\n",
    "\n",
    "Run the first cell and then choose a plot type.\n",
    "\n",
    "Note that with analysis_type == AnalysisType.Residuals, these components are expected to be missing:\n",
    "\n",
    "- Distributed Generation\n",
    "\n",
    "and with analysis_type == AnalysisType.Modeled, these components are expected to be missing:\n",
    "\n",
    "- Residential Gaps (included in Residential in this case)\n",
    "- CHP and Thermal DG (combined with Distributed PV in Distributed Generation)\n",
    "- Distributed PV (combined with CHP and Thermal DG in Distributed Generation)\n",
    "- Loss Model\n",
    "- Hourly Residuals\n",
    "- Top-Down Hourly\n",
    "- Top-Down Annual Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d9e0f",
   "metadata": {},
   "source": [
    "⚠️ **WARNING** ⚠️ This cell can take a long time to run the first time, especially over s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CONUS model if it does not exist or overwrite is True\n",
    "model_name = 'conus_hourly_residuals' if analysis_type == AnalysisType.Residuals else \"dsgrid_site_energy_conus_hourly\"\n",
    "model_path = output_dir / model_name\n",
    "if model_path.exists() and overwrite:\n",
    "    logger.info(f\"Deleting {model_path} and re-creating. If this \"\n",
    "                \"is not the desired behavior, set overwrite = False.\")\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "if not model_path.exists():\n",
    "    model = get_model(dsgrid_dataset_path)\n",
    "    model.map_dimension(model_path, conus, mappings)\n",
    "model = get_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18129d",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Sectors\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 19. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"conus\"\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "seasonal_example_weeks_sectors(model, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2375a7",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e41e6",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Residuals\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 20. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fafe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"conus\"\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "    \n",
    "seasonal_example_weeks_residuals(model, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb2b72",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2ae63",
   "metadata": {},
   "source": [
    "### Seasonal Diurnal Profiles\n",
    "\n",
    "Requires AnalysisType.Modeled. Produces plots similar to dsgrid Model Documentation Figures 23, 24, 25. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running, as well as the True/False options in the call to `seasonal_diurnal_profiles`.\n",
    "\n",
    "⚠️ **WARNING** ⚠️ This cell can take a long time to run and can produce many figures. Setting show to False and deselecting figure types that are not of interest can mitigate runtime and other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Modeled, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce these plots go back to 'Choose analysis type' and input 'AnalysisType.Modeled'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = False\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_diurnal_profiles\" / \"conus\"\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "options = OptionPresenter(list(model.keys()))\n",
    "options.present_options(name_func = lambda x: x[1])\n",
    "input_str = input(\"Which component's data would you like to plot (input number)? \")\n",
    "component_id = options.get_option(input_str)\n",
    "\n",
    "seasonal_diurnal_profiles(model, component_id, plots_dir = plots_dir, show=show, \n",
    "                          subsector_plot=True, enduse_plot=True, enduse_by_subsector_plots=True,\n",
    "                          area_plots=True, line_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1a577",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda772cd",
   "metadata": {},
   "source": [
    "## Census Divisions\n",
    "\n",
    "Run the first two cells and then choose a plot type.\n",
    "\n",
    "Note that with analysis_type == AnalysisType.Residuals, these components are expected to be missing:\n",
    "\n",
    "- Distributed Generation\n",
    "\n",
    "and with analysis_type == AnalysisType.Modeled, these components are expected to be missing:\n",
    "\n",
    "- Residential Gaps (included in Residential in this case)\n",
    "- CHP and Thermal DG (combined with Distributed PV in Distributed Generation)\n",
    "- Distributed PV (combined with CHP and Thermal DG in Distributed Generation)\n",
    "- Loss Model\n",
    "- Hourly Residuals\n",
    "- Top-Down Hourly\n",
    "- Top-Down Annual Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed7b5a",
   "metadata": {},
   "source": [
    "⚠️ **WARNING** ⚠️ This cell can take a long time to run the first time, especially over s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Census Divisions model if it does not exist or overwrite is True\n",
    "model_name = 'census_division_hourly_residuals' if analysis_type == AnalysisType.Residuals else \"dsgrid_site_energy_census_division_hourly\"\n",
    "model_path = output_dir / model_name\n",
    "if model_path.exists() and overwrite:\n",
    "    logger.info(f\"Deleting {model_path} and re-creating. If this \"\n",
    "                \"is not the desired behavior, set overwrite = False.\")\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "if not model_path.exists():\n",
    "    model = get_model(dsgrid_dataset_path)\n",
    "    model.map_dimension(model_path, census_divisions, mappings)\n",
    "model = get_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad89b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_enum = model.components[(ComponentType(ComponentType.BOTTOMUP),'Residential')].datafile.geo_enum\n",
    "\n",
    "options = OptionPresenter(geo_enum.ids)\n",
    "options.present_options(name_func = geo_enum.get_name)\n",
    "input_str = input(\"Which census division would you like to examine (input number)? \")\n",
    "geo_id = options.get_option(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419ebcc",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Sectors\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 19. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"census_divisions\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "seasonal_example_weeks_sectors(model, geo_id=geo_id, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405f14d",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce877b96",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Residuals\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 20. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"census_divisions\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "    \n",
    "seasonal_example_weeks_residuals(model, geo_id=geo_id, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e82a45",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d146d3",
   "metadata": {},
   "source": [
    "### Seasonal Diurnal Profiles\n",
    "\n",
    "Requires AnalysisType.Modeled. Produces plots similar to dsgrid Model Documentation Figures 23, 24, 25. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running, as well as the True/False options in the call to `seasonal_diurnal_profiles`.\n",
    "\n",
    "⚠️ **WARNING** ⚠️ This cell can take a long time to run and can produce many figures. Setting show to False and deselecting figure types that are not of interest can mitigate runtime and other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af665fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Modeled, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce these plots go back to 'Choose analysis type' and input 'AnalysisType.Modeled'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = False\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_diurnal_profiles\" / \"census_divisions\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "options = OptionPresenter(list(model.keys()))\n",
    "options.present_options(name_func = lambda x: x[1])\n",
    "input_str = input(\"Which component's data would you like to plot (input number)? \")\n",
    "component_id = options.get_option(input_str)\n",
    "\n",
    "seasonal_diurnal_profiles(model, component_id, geo_id=geo_id, plots_dir=plots_dir, show=show, \n",
    "                          subsector_plot=True, enduse_plot=True, enduse_by_subsector_plots=True,\n",
    "                          area_plots=True, line_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768a6ae",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdd329",
   "metadata": {},
   "source": [
    "## States\n",
    "\n",
    "Run the first two cells and then choose a plot type.\n",
    "\n",
    "Note that with analysis_type == AnalysisType.Residuals, these components are expected to be missing:\n",
    "\n",
    "- Distributed Generation\n",
    "\n",
    "and with analysis_type == AnalysisType.Modeled, these components are expected to be missing:\n",
    "\n",
    "- Residential Gaps (included in Residential in this case)\n",
    "- CHP and Thermal DG (combined with Distributed PV in Distributed Generation)\n",
    "- Distributed PV (combined with CHP and Thermal DG in Distributed Generation)\n",
    "- Loss Model\n",
    "- Hourly Residuals\n",
    "- Top-Down Hourly\n",
    "- Top-Down Annual Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55380f",
   "metadata": {},
   "source": [
    "⚠️ **WARNING** ⚠️ This cell can take a while to run over s3 and/or slow network connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42295cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(dsgrid_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_enum = conus_states\n",
    "\n",
    "options = OptionPresenter(geo_enum.ids)\n",
    "options.present_options(name_func = geo_enum.get_name)\n",
    "input_str = input(\"Which state would you like to examine (input number)? \")\n",
    "geo_id = options.get_option(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4554be",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Sectors\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 19. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"states\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "seasonal_example_weeks_sectors(model, geo_id=geo_id, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e36d3c",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46955543",
   "metadata": {},
   "source": [
    "### Seasonal Example Weeks - Residuals\n",
    "\n",
    "Requires AnalysisType.Residuals. Produces plots similar to dsgrid Model Documentation Figure 20. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Residuals, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce this plot go back to 'Choose analysis type' and input 'AnalysisType.Residuals'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = True\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_example_weeks\" / \"states\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "    \n",
    "seasonal_example_weeks_residuals(model, geo_id=geo_id, plots_dir=plots_dir, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfc66a",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40628b3b",
   "metadata": {},
   "source": [
    "### Seasonal Diurnal Profiles\n",
    "\n",
    "Requires AnalysisType.Modeled. Produces plots similar to dsgrid Model Documentation Figures 23, 24, 25. \n",
    "\n",
    "Be sure to review the show and plots_dir arguments before running, as well as the True/False options in the call to `seasonal_diurnal_profiles`.\n",
    "\n",
    "⚠️ **WARNING** ⚠️ This cell can take a long time to run and can produce many figures. Setting show to False and deselecting figure types that are not of interest can mitigate runtime and other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis_type == AnalysisType.Modeled, (f\"Wrong analysis_type {analysis_type!r}. To \"\n",
    "    \"produce these plots go back to 'Choose analysis type' and input 'AnalysisType.Modeled'; \"\n",
    "    \"then re-run the top part of this section before re-running this cell.\")\n",
    "\n",
    "# USER INPUT ----------------------------------------\n",
    "# \n",
    "# Whether to show plots in this notebook\n",
    "show = False\n",
    "# Output directory for .png files -- set to None if not desired\n",
    "plots_dir = output_dir / \"seasonal_diurnal_profiles\" / \"states\" / geo_id\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if plots_dir is not None:\n",
    "    make_dir(plots_dir)\n",
    "\n",
    "options = OptionPresenter(list(model.keys()))\n",
    "options.present_options(name_func = lambda x: x[1])\n",
    "input_str = input(\"Which component's data would you like to plot (input number)? \")\n",
    "component_id = options.get_option(input_str)\n",
    "\n",
    "seasonal_diurnal_profiles(model, component_id, geo_id=geo_id, plots_dir=plots_dir, show=show, \n",
    "                          subsector_plot=True, enduse_plot=True, enduse_by_subsector_plots=True,\n",
    "                          area_plots=True, line_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c957c8",
   "metadata": {},
   "source": [
    "[Choose analysis type](#Choose-analysis-type) | [Contiguous United States](#Contiguous-United-States) | [Census Divisions](#Census-Divisions) | [States](#States)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
